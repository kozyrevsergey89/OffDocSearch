'''
Server for web crawler instance
@author: David Mayboroda
'''
from BaseHTTPServer import BaseHTTPRequestHandler, HTTPServer
from web_crawler import WebCrawler
from json_generator import generate_json

class OffDocsHandler(BaseHTTPRequestHandler):
    
    def do_GET(self):
        try:
            global wc_dev, wc_itpro
            self.send_response(200)
            self.send_header('Content-type','text/html')
            self.end_headers()
            prof, key = self.parse_params();
            if prof == "dev":
                self.wfile.write(wc_dev.lookup(key))
            elif prof == "itpro":
                print wc_itpro.index
                self.wfile.write(wc_itpro.lookup(key))
            #self.wfile.write(generate_json(wc_dev.lookup('Android')))
         
        except IOError:
            self.send_error(404,'File Not Found: %s' % self.path)
    
    def parse_params(self):
        qprof = self.path[self.path.find("=")+1 : self.path.find("&")]
        keyword = self.path[self.path.rfind("=")+1: :]
        return qprof, keyword

wc_dev = None
wc_itpro = None
def main():
    try:
        global wc_dev, wc_itpro
        wc_dev = WebCrawler()
        wc_itpro = WebCrawler()
        wc_dev.crawl_web("dev")
        wc_itpro.crawl_web("itpro")
        server = HTTPServer(('', 8080), OffDocsHandler)
        print 'started http server...'
        server.serve_forever()
    except KeyboardInterrupt:
        print 'shutting down server'
        server.socket.close()

if __name__ == '__main__':
    main()